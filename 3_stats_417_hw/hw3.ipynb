{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and normalize CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.5, 0.5, 0.5),\n",
    "            (0.5, 0.5, 0.5)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat   ship  cat   horse\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Defining CNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Original neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_1(nn.Module):\n",
    "    \"\"\"\n",
    "    Doubling the number of channels in each layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(12, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_2(nn.Module):\n",
    "    \"\"\"\n",
    "    Decrease to 1 convolutional layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.fc1 = nn.Linear(1350, 120)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "        #self.fc3 = nn.Linear(30, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #x = torch.flatten(x,1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class Net_3(nn.Module):\n",
    "    \"\"\"\n",
    "    Increase to 3 convolutional layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.fc1 = nn.Linear(128, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 24)\n",
    "        self.fc4 = nn.Linear(24, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class Net_4(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation Function: LeakyReLU\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.1)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.LeakyReLU(self.conv1(x)))\n",
    "        x = self.pool(self.LeakyReLU(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.LeakyReLU(self.fc1(x))\n",
    "        x = self.LeakyReLU(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_5(nn.Module):\n",
    "    \"\"\"\n",
    "    Activation Function: Tanh\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.Tanh = nn.Tanh()\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.Tanh(self.conv1(x)))\n",
    "        x = self.pool(self.Tanh(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.Tanh(self.fc1(x))\n",
    "        x = self.Tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "net   = Net()\n",
    "net_1 = Net_1()\n",
    "net_2 = Net_2()\n",
    "net_3 = Net_3()\n",
    "net_4 = Net_4()\n",
    "net_5 = Net_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(neural_net):\n",
    "    \n",
    "    # define a loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    # saving the model\n",
    "    # torch.save(neural_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.266\n",
      "[1,  4000] loss: 1.891\n",
      "[1,  6000] loss: 1.663\n",
      "[1,  8000] loss: 1.574\n",
      "[1, 10000] loss: 1.519\n",
      "[1, 12000] loss: 1.484\n",
      "[2,  2000] loss: 1.404\n",
      "[2,  4000] loss: 1.387\n",
      "[2,  6000] loss: 1.355\n",
      "[2,  8000] loss: 1.340\n",
      "[2, 10000] loss: 1.310\n",
      "[2, 12000] loss: 1.293\n",
      "Finished Training\n",
      "[1,  2000] loss: 2.190\n",
      "[1,  4000] loss: 1.825\n",
      "[1,  6000] loss: 1.612\n",
      "[1,  8000] loss: 1.528\n",
      "[1, 10000] loss: 1.437\n",
      "[1, 12000] loss: 1.386\n",
      "[2,  2000] loss: 1.310\n",
      "[2,  4000] loss: 1.291\n",
      "[2,  6000] loss: 1.240\n",
      "[2,  8000] loss: 1.194\n",
      "[2, 10000] loss: 1.198\n",
      "[2, 12000] loss: 1.193\n",
      "Finished Training\n",
      "[1,  2000] loss: 1.893\n",
      "[1,  4000] loss: 1.621\n",
      "[1,  6000] loss: 1.514\n",
      "[1,  8000] loss: 1.488\n",
      "[1, 10000] loss: 1.443\n",
      "[1, 12000] loss: 1.423\n",
      "[2,  2000] loss: 1.316\n",
      "[2,  4000] loss: 1.311\n",
      "[2,  6000] loss: 1.282\n",
      "[2,  8000] loss: 1.280\n",
      "[2, 10000] loss: 1.258\n",
      "[2, 12000] loss: 1.274\n",
      "Finished Training\n",
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.303\n",
      "[1,  6000] loss: 2.302\n",
      "[1,  8000] loss: 2.239\n",
      "[1, 10000] loss: 2.041\n",
      "[1, 12000] loss: 1.861\n",
      "[2,  2000] loss: 1.692\n",
      "[2,  4000] loss: 1.633\n",
      "[2,  6000] loss: 1.553\n",
      "[2,  8000] loss: 1.517\n",
      "[2, 10000] loss: 1.458\n",
      "[2, 12000] loss: 1.448\n",
      "Finished Training\n",
      "[1,  2000] loss: 2.152\n",
      "[1,  4000] loss: 1.812\n",
      "[1,  6000] loss: 1.653\n",
      "[1,  8000] loss: 1.568\n",
      "[1, 10000] loss: 1.512\n",
      "[1, 12000] loss: 1.462\n",
      "[2,  2000] loss: 1.382\n",
      "[2,  4000] loss: 1.368\n",
      "[2,  6000] loss: 1.347\n",
      "[2,  8000] loss: 1.318\n",
      "[2, 10000] loss: 1.310\n",
      "[2, 12000] loss: 1.279\n",
      "Finished Training\n",
      "[1,  2000] loss: 2.036\n",
      "[1,  4000] loss: 1.730\n",
      "[1,  6000] loss: 1.596\n",
      "[1,  8000] loss: 1.493\n",
      "[1, 10000] loss: 1.462\n",
      "[1, 12000] loss: 1.432\n",
      "[2,  2000] loss: 1.361\n",
      "[2,  4000] loss: 1.343\n",
      "[2,  6000] loss: 1.309\n",
      "[2,  8000] loss: 1.282\n",
      "[2, 10000] loss: 1.273\n",
      "[2, 12000] loss: 1.251\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_net(net)\n",
    "train_net(net_1)\n",
    "train_net(net_2)\n",
    "train_net(net_3)\n",
    "train_net(net_4)\n",
    "train_net(net_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "#imshow(torchvision.utils.make_grid(images))\n",
    "#print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_accuracy(neural_net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = neural_net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_accuracy(neural_net):\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = neural_net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "doubling the number of channels\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"doubling the number of channels\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy for class: plane is 62.9 %\n",
      "Accuracy for class: car   is 66.1 %\n",
      "Accuracy for class: bird  is 51.6 %\n",
      "Accuracy for class: cat   is 37.3 %\n",
      "Accuracy for class: deer  is 34.2 %\n",
      "Accuracy for class: dog   is 50.1 %\n",
      "Accuracy for class: frog  is 59.5 %\n",
      "Accuracy for class: horse is 69.4 %\n",
      "Accuracy for class: ship  is 73.2 %\n",
      "Accuracy for class: truck is 65.1 %\n",
      "doubling the number of channels\n",
      "----------\n",
      "Accuracy for class: plane is 51.1 %\n",
      "Accuracy for class: car   is 77.3 %\n",
      "Accuracy for class: bird  is 54.0 %\n",
      "Accuracy for class: cat   is 43.5 %\n",
      "Accuracy for class: deer  is 62.0 %\n",
      "Accuracy for class: dog   is 41.8 %\n",
      "Accuracy for class: frog  is 75.9 %\n",
      "Accuracy for class: horse is 55.5 %\n",
      "Accuracy for class: ship  is 78.6 %\n",
      "Accuracy for class: truck is 53.6 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"doubling the number of channels\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the number of convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "\n",
      "decrease to 1 convolutional layer\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "\n",
      "increase to 3 convolutional layer\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"decrease to 1 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net_2)\n",
    "print(\"\")\n",
    "print(\"increase to 3 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy for class: plane is 57.4 %\n",
      "Accuracy for class: car   is 71.8 %\n",
      "Accuracy for class: bird  is 37.2 %\n",
      "Accuracy for class: cat   is 16.0 %\n",
      "Accuracy for class: deer  is 38.9 %\n",
      "Accuracy for class: dog   is 53.4 %\n",
      "Accuracy for class: frog  is 84.2 %\n",
      "Accuracy for class: horse is 67.7 %\n",
      "Accuracy for class: ship  is 71.8 %\n",
      "Accuracy for class: truck is 62.7 %\n",
      "decrease to 1 convolutional layer\n",
      "----------\n",
      "Accuracy for class: plane is 57.5 %\n",
      "Accuracy for class: car   is 60.1 %\n",
      "Accuracy for class: bird  is 37.2 %\n",
      "Accuracy for class: cat   is 36.1 %\n",
      "Accuracy for class: deer  is 47.2 %\n",
      "Accuracy for class: dog   is 46.4 %\n",
      "Accuracy for class: frog  is 60.1 %\n",
      "Accuracy for class: horse is 73.3 %\n",
      "Accuracy for class: ship  is 73.6 %\n",
      "Accuracy for class: truck is 70.6 %\n",
      "increase to 3 convolutional layer\n",
      "----------\n",
      "Accuracy for class: plane is 44.5 %\n",
      "Accuracy for class: car   is 63.6 %\n",
      "Accuracy for class: bird  is 37.0 %\n",
      "Accuracy for class: cat   is 11.6 %\n",
      "Accuracy for class: deer  is 29.3 %\n",
      "Accuracy for class: dog   is 61.0 %\n",
      "Accuracy for class: frog  is 54.3 %\n",
      "Accuracy for class: horse is 55.2 %\n",
      "Accuracy for class: ship  is 76.1 %\n",
      "Accuracy for class: truck is 54.9 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"decrease to 1 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net_2)\n",
    "print(\"\")\n",
    "print(\"increase to 3 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "\n",
      "decrease to 1 convolutional layer\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 56 %\n",
      "\n",
      "increase to 3 convolutional layer\n",
      "----------\n",
      "Accuracy of the network on the 10000 test images: 48 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"decrease to 1 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net_2)\n",
    "print(\"\")\n",
    "print(\"increase to 3 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_total_accuracy(net_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original CNN from tutorial\n",
      "----------\n",
      "Accuracy for class: plane is 57.4 %\n",
      "Accuracy for class: car   is 71.8 %\n",
      "Accuracy for class: bird  is 37.2 %\n",
      "Accuracy for class: cat   is 16.0 %\n",
      "Accuracy for class: deer  is 38.9 %\n",
      "Accuracy for class: dog   is 53.4 %\n",
      "Accuracy for class: frog  is 84.2 %\n",
      "Accuracy for class: horse is 67.7 %\n",
      "Accuracy for class: ship  is 71.8 %\n",
      "Accuracy for class: truck is 62.7 %\n",
      "\n",
      "decrease to 1 convolutional layer\n",
      "----------\n",
      "Accuracy for class: plane is 57.5 %\n",
      "Accuracy for class: car   is 60.1 %\n",
      "Accuracy for class: bird  is 37.2 %\n",
      "Accuracy for class: cat   is 36.1 %\n",
      "Accuracy for class: deer  is 47.2 %\n",
      "Accuracy for class: dog   is 46.4 %\n",
      "Accuracy for class: frog  is 60.1 %\n",
      "Accuracy for class: horse is 73.3 %\n",
      "Accuracy for class: ship  is 73.6 %\n",
      "Accuracy for class: truck is 70.6 %\n",
      "\n",
      "increase to 3 convolutional layer\n",
      "----------\n",
      "Accuracy for class: plane is 44.5 %\n",
      "Accuracy for class: car   is 63.6 %\n",
      "Accuracy for class: bird  is 37.0 %\n",
      "Accuracy for class: cat   is 11.6 %\n",
      "Accuracy for class: deer  is 29.3 %\n",
      "Accuracy for class: dog   is 61.0 %\n",
      "Accuracy for class: frog  is 54.3 %\n",
      "Accuracy for class: horse is 55.2 %\n",
      "Accuracy for class: ship  is 76.1 %\n",
      "Accuracy for class: truck is 54.9 %\n"
     ]
    }
   ],
   "source": [
    "print(\"original CNN from tutorial\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"decrease to 1 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net_2)\n",
    "print(\"\")\n",
    "print(\"increase to 3 convolutional layer\")\n",
    "print(\"-\"*10)\n",
    "get_group_accuracy(net_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Changing the training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_parameters(neural_net, lr):\n",
    "    \n",
    "    # define a loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(neural_net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    # saving the model\n",
    "    # torch.save(neural_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_train_accuracy(neural_net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = neural_net(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_train_accuracy(neural_net):\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "    with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            images, labels = data\n",
    "            outputs = neural_net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Learning Rate: 0.0001\n",
      "----------\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "Accuracy for class: plane is 51.2 %\n",
      "Accuracy for class: car   is 59.0 %\n",
      "Accuracy for class: bird  is 26.4 %\n",
      "Accuracy for class: cat   is 34.5 %\n",
      "Accuracy for class: deer  is 35.6 %\n",
      "Accuracy for class: dog   is 38.0 %\n",
      "Accuracy for class: frog  is 55.4 %\n",
      "Accuracy for class: horse is 54.4 %\n",
      "Accuracy for class: ship  is 58.2 %\n",
      "Accuracy for class: truck is 51.8 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "Accuracy for class: plane is 55.1 %\n",
      "Accuracy for class: car   is 69.0 %\n",
      "Accuracy for class: bird  is 32.2 %\n",
      "Accuracy for class: cat   is 39.2 %\n",
      "Accuracy for class: deer  is 39.6 %\n",
      "Accuracy for class: dog   is 42.5 %\n",
      "Accuracy for class: frog  is 56.9 %\n",
      "Accuracy for class: horse is 60.6 %\n",
      "Accuracy for class: ship  is 64.6 %\n",
      "Accuracy for class: truck is 59.6 %\n",
      "\n",
      "Finished Training\n",
      "Learning Rate: 0.001\n",
      "----------\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "Accuracy for class: plane is 50.3 %\n",
      "Accuracy for class: car   is 61.3 %\n",
      "Accuracy for class: bird  is 27.8 %\n",
      "Accuracy for class: cat   is 31.3 %\n",
      "Accuracy for class: deer  is 35.4 %\n",
      "Accuracy for class: dog   is 42.4 %\n",
      "Accuracy for class: frog  is 56.6 %\n",
      "Accuracy for class: horse is 55.3 %\n",
      "Accuracy for class: ship  is 58.7 %\n",
      "Accuracy for class: truck is 49.2 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "Accuracy for class: plane is 56.3 %\n",
      "Accuracy for class: car   is 71.8 %\n",
      "Accuracy for class: bird  is 34.1 %\n",
      "Accuracy for class: cat   is 37.5 %\n",
      "Accuracy for class: deer  is 38.5 %\n",
      "Accuracy for class: dog   is 46.3 %\n",
      "Accuracy for class: frog  is 58.9 %\n",
      "Accuracy for class: horse is 62.3 %\n",
      "Accuracy for class: ship  is 66.3 %\n",
      "Accuracy for class: truck is 60.3 %\n",
      "\n",
      "Finished Training\n",
      "Learning Rate: 0.01\n",
      "----------\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 45 %\n",
      "Accuracy for class: plane is 48.8 %\n",
      "Accuracy for class: car   is 58.6 %\n",
      "Accuracy for class: bird  is 13.4 %\n",
      "Accuracy for class: cat   is 18.7 %\n",
      "Accuracy for class: deer  is 46.4 %\n",
      "Accuracy for class: dog   is 50.9 %\n",
      "Accuracy for class: frog  is 52.8 %\n",
      "Accuracy for class: horse is 53.7 %\n",
      "Accuracy for class: ship  is 61.7 %\n",
      "Accuracy for class: truck is 47.8 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 51 %\n",
      "Accuracy for class: plane is 53.0 %\n",
      "Accuracy for class: car   is 70.0 %\n",
      "Accuracy for class: bird  is 17.9 %\n",
      "Accuracy for class: cat   is 24.9 %\n",
      "Accuracy for class: deer  is 50.4 %\n",
      "Accuracy for class: dog   is 57.1 %\n",
      "Accuracy for class: frog  is 54.7 %\n",
      "Accuracy for class: horse is 61.4 %\n",
      "Accuracy for class: ship  is 71.0 %\n",
      "Accuracy for class: truck is 57.6 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0.0001,0.001,0.01]:\n",
    "    train_net_parameters(net, i)\n",
    "    print(f\"Learning Rate: {i}\")\n",
    "    print(\"-\"*10)\n",
    "    print(\"test accuracy\")\n",
    "    get_total_accuracy(net)\n",
    "    get_group_accuracy(net)\n",
    "    print(\"\")\n",
    "    print(\"train accuracy\")\n",
    "    get_total_train_accuracy(net)\n",
    "    get_group_train_accuracy(net)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_parameters(neural_net, optimizer, lr=0.001):\n",
    "    \n",
    "    # define a loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(neural_net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    # saving the model\n",
    "    # torch.save(neural_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "----------\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "Accuracy for class: plane is 50.7 %\n",
      "Accuracy for class: car   is 60.3 %\n",
      "Accuracy for class: bird  is 27.1 %\n",
      "Accuracy for class: cat   is 32.7 %\n",
      "Accuracy for class: deer  is 37.3 %\n",
      "Accuracy for class: dog   is 39.6 %\n",
      "Accuracy for class: frog  is 56.6 %\n",
      "Accuracy for class: horse is 55.7 %\n",
      "Accuracy for class: ship  is 57.8 %\n",
      "Accuracy for class: truck is 51.8 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 53 %\n",
      "Accuracy for class: plane is 55.3 %\n",
      "Accuracy for class: car   is 71.8 %\n",
      "Accuracy for class: bird  is 33.8 %\n",
      "Accuracy for class: cat   is 39.8 %\n",
      "Accuracy for class: deer  is 43.0 %\n",
      "Accuracy for class: dog   is 45.0 %\n",
      "Accuracy for class: frog  is 58.0 %\n",
      "Accuracy for class: horse is 62.9 %\n",
      "Accuracy for class: ship  is 67.6 %\n",
      "Accuracy for class: truck is 62.4 %\n",
      "\n",
      "Finished Training\n",
      "----------\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "Accuracy for class: plane is 52.8 %\n",
      "Accuracy for class: car   is 64.6 %\n",
      "Accuracy for class: bird  is 34.8 %\n",
      "Accuracy for class: cat   is 28.9 %\n",
      "Accuracy for class: deer  is 40.1 %\n",
      "Accuracy for class: dog   is 38.7 %\n",
      "Accuracy for class: frog  is 58.7 %\n",
      "Accuracy for class: horse is 49.5 %\n",
      "Accuracy for class: ship  is 52.8 %\n",
      "Accuracy for class: truck is 50.3 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 57 %\n",
      "Accuracy for class: plane is 62.7 %\n",
      "Accuracy for class: car   is 80.7 %\n",
      "Accuracy for class: bird  is 42.5 %\n",
      "Accuracy for class: cat   is 40.6 %\n",
      "Accuracy for class: deer  is 46.8 %\n",
      "Accuracy for class: dog   is 46.8 %\n",
      "Accuracy for class: frog  is 62.6 %\n",
      "Accuracy for class: horse is 61.1 %\n",
      "Accuracy for class: ship  is 68.4 %\n",
      "Accuracy for class: truck is 65.9 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer_SGD_no_momentum = optim.SGD(net.parameters(), momentum=0.0, lr=0.001)\n",
    "optimizer_Adam = optim.Adam(net.parameters())\n",
    "\n",
    "for i in [optimizer_SGD_no_momentum, optimizer_Adam]:\n",
    "    train_net_parameters(net, optimizer = i)\n",
    "    print(\"-\"*10)\n",
    "    print(\"test accuracy\")\n",
    "    get_total_accuracy(net)\n",
    "    get_group_accuracy(net)\n",
    "    print(\"\")\n",
    "    print(\"train accuracy\")\n",
    "    get_total_train_accuracy(net)\n",
    "    get_group_train_accuracy(net)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larger batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "Accuracy for class: plane is 50.1 %\n",
      "Accuracy for class: car   is 57.4 %\n",
      "Accuracy for class: bird  is 34.2 %\n",
      "Accuracy for class: cat   is 30.5 %\n",
      "Accuracy for class: deer  is 35.7 %\n",
      "Accuracy for class: dog   is 40.3 %\n",
      "Accuracy for class: frog  is 53.8 %\n",
      "Accuracy for class: horse is 57.0 %\n",
      "Accuracy for class: ship  is 60.1 %\n",
      "Accuracy for class: truck is 53.9 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "Accuracy for class: plane is 65.4 %\n",
      "Accuracy for class: car   is 78.4 %\n",
      "Accuracy for class: bird  is 45.2 %\n",
      "Accuracy for class: cat   is 45.4 %\n",
      "Accuracy for class: deer  is 45.6 %\n",
      "Accuracy for class: dog   is 51.2 %\n",
      "Accuracy for class: frog  is 60.2 %\n",
      "Accuracy for class: horse is 70.4 %\n",
      "Accuracy for class: ship  is 76.8 %\n",
      "Accuracy for class: truck is 73.5 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "train_net(net)\n",
    "print(\"test accuracy\")\n",
    "get_total_accuracy(net)\n",
    "get_group_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"train accuracy\")\n",
    "get_total_train_accuracy(net)\n",
    "get_group_train_accuracy(net)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_parameters(neural_net, num_epochs):\n",
    "    \n",
    "    # define a loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(neural_net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = neural_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    # saving the model\n",
    "    # torch.save(neural_net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "test accuracy\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "Accuracy for class: plane is 48.2 %\n",
      "Accuracy for class: car   is 58.4 %\n",
      "Accuracy for class: bird  is 36.0 %\n",
      "Accuracy for class: cat   is 30.3 %\n",
      "Accuracy for class: deer  is 34.0 %\n",
      "Accuracy for class: dog   is 36.9 %\n",
      "Accuracy for class: frog  is 57.7 %\n",
      "Accuracy for class: horse is 57.9 %\n",
      "Accuracy for class: ship  is 59.0 %\n",
      "Accuracy for class: truck is 55.5 %\n",
      "\n",
      "train accuracy\n",
      "Accuracy of the network on the 10000 test images: 60 %\n",
      "Accuracy for class: plane is 62.8 %\n",
      "Accuracy for class: car   is 78.1 %\n",
      "Accuracy for class: bird  is 45.6 %\n",
      "Accuracy for class: cat   is 44.2 %\n",
      "Accuracy for class: deer  is 44.0 %\n",
      "Accuracy for class: dog   is 47.3 %\n",
      "Accuracy for class: frog  is 63.6 %\n",
      "Accuracy for class: horse is 70.8 %\n",
      "Accuracy for class: ship  is 75.4 %\n",
      "Accuracy for class: truck is 74.6 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_net_parameters(net, num_epochs=5)\n",
    "print(\"test accuracy\")\n",
    "get_total_accuracy(net)\n",
    "get_group_accuracy(net)\n",
    "print(\"\")\n",
    "print(\"train accuracy\")\n",
    "get_total_train_accuracy(net)\n",
    "get_group_train_accuracy(net)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dimension - represents the size of the input at each time step  \n",
    "Hidden dimension - the number of nodes in the hidden layer at time t  \n",
    "Number of layers - total number of LSTM layers in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 10\n",
    "n_layers = 1\n",
    "\n",
    "lstm_layer = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "seq_len = 1\n",
    "\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "hidden_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "cell_state = torch.randn(n_layers, batch_size, hidden_dim)\n",
    "hidden = (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm_layer(inp, hidden)\n",
    "print(\"Output shape: \", out.shape)\n",
    "print(\"Hidden: \", hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM takes as input a sequence of variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "inp = torch.randn(batch_size, seq_len, input_dim)\n",
    "out, hidden = lstm_layer(inp, hidden)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the last output\n",
    "out = out.squeeze()[-1, :]\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Review Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "\n",
    "train_file = bz2.BZ2File('../input/amazon_reviews/train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('../input/amazon_reviews/test.ft.txt.bz2')\n",
    "\n",
    "train_file = train_file.readlines()\n",
    "test_file = test_file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the data and split train vs test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 800000  # We're training on the first 800,000 reviews in the dataset\n",
    "num_test = 200000  # Using 200,000 reviews from test set\n",
    "\n",
    "train_file = [x.decode('utf-8') for x in train_file[:num_train]]\n",
    "test_file = [x.decode('utf-8') for x in test_file[:num_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we extract the labels from train and test sets as well as do some data cleaning to format URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting labels from sentences\n",
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\n",
    "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]\n",
    "\n",
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]\n",
    "\n",
    "# Some simple cleaning of data\n",
    "for i in range(len(train_sentences)):\n",
    "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
    "\n",
    "# Modify URLs to <url>\n",
    "for i in range(len(train_sentences)):\n",
    "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
    "        \n",
    "for i in range(len(test_sentences)):\n",
    "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we tokenize each word using the nltk library and perform some additional tranformations that change all words to lowercase and remove words that only appear once. Making all words lowercase ensures that the same word is tokenized to the same value; otherwise, a capitalized word would be considered different than the same word in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Counter()  # Dictionary that will map a word to the number of times it appeared in all the training sentences\n",
    "for i, sentence in enumerate(train_sentences):\n",
    "    # The sentences will be stored as a list of words/tokens\n",
    "    train_sentences[i] = []\n",
    "    for word in nltk.word_tokenize(sentence):  # Tokenizing the words\n",
    "        words.update([word.lower()])  # Converting all the words to lowercase\n",
    "        train_sentences[i].append(word)\n",
    "    if i%20000 == 0:\n",
    "        print(str((i*100)/num_train) + \"% done\")\n",
    "print(\"100% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the words that only appear once\n",
    "words = {k:v for k,v in words.items() if v>1}\n",
    "# Sorting the words according to the number of appearances, with the most common word being first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "words = ['_PAD','_UNK'] + words\n",
    "# Dictionaries to store the word to index mappings and vice versa\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(train_sentences):\n",
    "    # Looking up the mapping dictionary and assigning the index to the respective words\n",
    "    train_sentences[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]\n",
    "\n",
    "for i, sentence in enumerate(test_sentences):\n",
    "    # For test sentences, we have to tokenize the sentences as well\n",
    "    test_sentences[i] = [word2idx[word.lower()] if word.lower() in word2idx else 0 for word in nltk.word_tokenize(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pad the sentences so they are all the same length. This ensures that training in batches is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\n",
    "def pad_input(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features\n",
    "\n",
    "seq_len = 200  # The length that the sentences will be padded/shortened to\n",
    "\n",
    "train_sentences = pad_input(train_sentences, seq_len)\n",
    "test_sentences = pad_input(test_sentences, seq_len)\n",
    "\n",
    "# Converting our labels into numpy arrays\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split test set into validation and test. Validation will act as the final dataset on which to test the model after repeated training, testing, and hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.5 # 50% validation, 50% test\n",
    "split_id = int(split_frac * len(test_sentences))\n",
    "val_sentences, test_sentences = test_sentences[:split_id], test_sentences[split_id:]\n",
    "val_labels, test_labels = test_labels[:split_id], test_labels[split_id:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the pre-processed data into tensors so we can work with them in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
    "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
    "\n",
    "batch_size = 400\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If GPUs are available, cuda allows us to run parallel processes and train the PyTorch model must faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the neural network architecture with LSTM layers and a sigmoid function after the last LSTM layer that results in fully-connected classification layer that categorizes whether the sentiment is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(SentimentNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        out = out.view(batch_size, -1)\n",
    "        out = out[:,-1]\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the SentimentNet class with 2 layers, each with embeddings dimension of 400 and 512 hidden nodes. We will use binary cross entropy loss as the loss function (because we are training a binary classifier) and Adam as the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "\n",
    "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "model.to(device)\n",
    "\n",
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is then trained across 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "counter = 0\n",
    "print_every = 1000\n",
    "clip = 5\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):\n",
    "    h = model.init_hidden(batch_size)\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        h = tuple([e.data for e in h])\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        output, h = model(inputs, h)\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if counter%print_every == 0:\n",
    "            val_h = model.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            model.eval()\n",
    "            for inp, lab in val_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                inp, lab = inp.to(device), lab.to(device)\n",
    "                out, val_h = model(inp, val_h)\n",
    "                val_loss = criterion(out.squeeze(), lab.float())\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "            model.train()\n",
    "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
    "            if np.mean(val_losses) <= valid_loss_min:\n",
    "                torch.save(model.state_dict(), './state_dict.pt')\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
    "                valid_loss_min = np.mean(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we save it to state_dict.pth and can load it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the best model\n",
    "model.load_state_dict(torch.load('./state_dict.pt'))\n",
    "\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "h = model.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    output, h = model(inputs, h)\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
